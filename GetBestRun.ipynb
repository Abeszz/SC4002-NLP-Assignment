{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model,Validation Accuracy,Train Loss,Test Accuracy,Epoch,Parameters\n",
    "Part 2 RNN,51.88,0.69,50.09,22,\"optimizer_type: SGD, learning_rate: 0.0001, momentum: 0.9, weight_decay: 0.0001, batch_size: 32, epochs: 100, patience: 10, model_type: RNN, rnn_type: RNN, num_layers: 3, use_bidirectional: False, use_dropout: False, use_batch_norm: False, use_layer_norm: False, aggregation_method: last_hidden, hidden_size: 64, output_size: 2, freeze_embeddings: True, oov_handling_method: none, embedding_dim: 100\"\n",
    "Part 3 RNN,51.31,0.69,49.53,22,\"optimizer_type: SGD, learning_rate: 0.001, momentum: 0.9, weight_decay: 0.0001, batch_size: 32, epochs: 100, patience: 10, model_type: RNN, rnn_type: RNN, num_layers: 2, use_bidirectional: False, use_dropout: True, use_batch_norm: True, use_layer_norm: True, aggregation_method: last_hidden, hidden_size: 128, output_size: 2, freeze_embeddings: False, oov_handling_method: unknown_token, embedding_dim: 100\"\n",
    "Part 3 CNN,78.99,0.2,79.08,18,\"optimizer_type: Adam, learning_rate: 0.001, momentum: 0.9, weight_decay: 0.0001, batch_size: 64, epochs: 100, patience: 10, model_type: CNN, num_filters: 128, filter_sizes: [2, 3], dropout_rate: 0.3, output_size: 2, freeze_embeddings: False, oov_handling_method: unknown_token, embedding_dim: 100, glove_file_path: glove.6B.100d.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = df.groupby(['optimizer_type', 'learning_rate', 'momentum', 'weight_decay',\n",
    "#                       'batch_size', 'epochs', 'patience', 'model_type', \n",
    "#                       'rnn_type', 'num_layers', 'use_bidirectional', \n",
    "#                       'use_dropout', 'use_batch_norm', 'use_layer_norm', \n",
    "#                       'aggregation_method', 'hidden_size', 'output_size', \n",
    "#                       'freeze_embeddings', 'oov_handling_method', \n",
    "#                       'embedding_dim', 'glove_file_path'])\n",
    "grouped = df.groupby(['optimizer_type', 'learning_rate', 'momentum', 'weight_decay',\n",
    "                      'batch_size', 'epochs', 'patience', 'model_type', \n",
    "                      'num_filters', 'filter_sizes', 'dropout_rate', \n",
    "                      'output_size', 'freeze_embeddings', 'oov_handling_method', \n",
    "                      'embedding_dim', 'glove_file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall performance extracted and saved to 'best_overall_performance.csv'.\n",
      "Full run of the best configuration saved to 'best_run_full_epochs.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to the single CSV file\n",
    "csv_file_path = './results/part3_cnn_results_all.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Group by relevant parameters\n",
    "# grouped = df.groupby(['optimizer_type', 'learning_rate', 'momentum', 'weight_decay',\n",
    "#                       'batch_size', 'epochs', 'patience', 'model_type', \n",
    "#                       'rnn_type', 'num_layers', 'use_bidirectional', \n",
    "#                       'use_dropout', 'use_batch_norm', 'use_layer_norm', \n",
    "#                       'aggregation_method', 'hidden_size', 'output_size', \n",
    "#                       'freeze_embeddings', 'oov_handling_method', \n",
    "#                       'embedding_dim', 'glove_file_path'])\n",
    "grouped = df.groupby(['optimizer_type', 'learning_rate', 'momentum', 'weight_decay',\n",
    "                      'batch_size', 'epochs', 'patience', 'model_type', \n",
    "                      'num_filters', 'filter_sizes', 'dropout_rate', \n",
    "                      'output_size', 'freeze_embeddings', 'oov_handling_method', \n",
    "                      'embedding_dim', 'glove_file_path'])\n",
    "\n",
    "# Initialize a list to store the results\n",
    "all_results = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    last_epoch_row = group.iloc[-1]  # Get the last row for this group\n",
    "    \n",
    "    # Extract performance metrics\n",
    "    last_performance = {\n",
    "        'Model': 'Part 2 RNN',\n",
    "        'Validation Accuracy': last_epoch_row['Validation Accuracy'],\n",
    "        'Train Loss': last_epoch_row['Train Loss'],\n",
    "        'Test Accuracy': last_epoch_row['Test Accuracy'],\n",
    "        'Epoch': last_epoch_row['Epoch'],\n",
    "        'Parameters': ', '.join([f\"{param}: {value}\" for param, value in zip(group.columns[:20], name)])  # Create a readable string of parameters\n",
    "    }\n",
    "\n",
    "    # Append to results\n",
    "    all_results.append((last_performance, group))  # Store both performance and group data\n",
    "\n",
    "# Create a DataFrame from all results\n",
    "results_df = pd.DataFrame([res[0] for res in all_results])\n",
    "\n",
    "# Find the overall best performance based on Validation Accuracy\n",
    "best_overall = results_df.loc[results_df['Test Accuracy'].idxmax()]\n",
    "\n",
    "# Get the best group's full data\n",
    "best_group = all_results[results_df['Test Accuracy'].idxmax()][1]\n",
    "\n",
    "# Prepare final output\n",
    "best_performance = {\n",
    "    'Model': 'Part 3 CNN',\n",
    "    'Validation Accuracy': best_overall['Validation Accuracy'],\n",
    "    'Train Loss': best_overall['Train Loss'],\n",
    "    'Test Accuracy': best_overall['Test Accuracy'],\n",
    "    'Epoch': best_overall['Epoch'],\n",
    "    'Parameters': best_overall['Parameters']\n",
    "}\n",
    "\n",
    "# Convert the best performance into a DataFrame for better readability\n",
    "best_df = pd.DataFrame([best_performance])\n",
    "\n",
    "# Save the best performance to a new CSV file\n",
    "best_df.to_csv('best_overall_performance.csv', index=False)\n",
    "\n",
    "# Save the full run of the best configuration to another CSV file\n",
    "best_group.to_csv('best_run_full_epochs.csv', index=False)\n",
    "\n",
    "print(\"Best overall performance extracted and saved to 'best_overall_performance.csv'.\")\n",
    "print(\"Full run of the best configuration saved to 'best_run_full_epochs.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
